{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scraping using BeautifulSoup, Pandas, and Requests/Splinter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Dependencies\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = 'all'\n",
    "\n",
    "\n",
    "import requests\n",
    "from splinter import Browser\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import time\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "from urls_list import * #where all urls and paths are saved"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NASA Mars News\n",
    "\n",
    "* **Scrape the NASA Mars News Site and collect the latest News Title and Paragraph Text. Assign the text to variables that we can reference later.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_latest_news():\n",
    "    #########################################################################################\n",
    "    #Scrape the latest news\n",
    "    #Returns news_title, news_p\n",
    "    #########################################################################################\n",
    "    \n",
    "    news_title, news_p = None, None\n",
    "    #Configure Browser\n",
    "    browser = Browser(browser_choice, executable_path=executable_path, headless=True)\n",
    "    try:\n",
    "        #Visit url\n",
    "        browser.visit(nasa_mars_news)\n",
    "        #bs object with lxml parser\n",
    "        time.sleep(4)#This is very important\n",
    "        soup = bs(browser.html, 'lxml')\n",
    "        news = soup.find('li', class_='slide').div.find(class_='list_text').find_all('div')\n",
    "        news_title, news_p = news[1].text, news[2].text\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "            \n",
    "    #Close browser to avoid resource issue\n",
    "    browser.quit()\n",
    "    \n",
    "    \n",
    "    return (news_title, news_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_title, news_p = scrape_latest_news()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"NASA's MAVEN Observes Martian Night Sky Pulsing in Ultraviolet Light\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'Vast areas of the Martian night sky pulse in ultraviolet light, according to images from NASA’s MAVEN spacecraft. The results are being used to illuminate complex circulation patterns in the Martian atmosphere.'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_title\n",
    "news_p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## JPL Mars Space Images - Featured Image\n",
    "\n",
    "* **Find the image url for the current Featured Mars Image and assign the url string to a variable called featured_image_url**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_featured_image_url():\n",
    "    \n",
    "    #########################################################################################\n",
    "    #Scrape the featured image url from nasa jpl site\n",
    "    #Returns featured_image_url\n",
    "    #########################################################################################\n",
    "    \n",
    "    featured_image_url = None\n",
    "    #Configure Browser\n",
    "    browser = Browser(browser_choice, executable_path=executable_path, headless=True)\n",
    "\n",
    "    try:\n",
    "        #Visit url\n",
    "        browser.visit(nasa_jpl)\n",
    "        #bs object with lxml parser\n",
    "        time.sleep(4)#This is very important\n",
    "        soup = bs(browser.html, 'lxml')\n",
    "\n",
    "        #Click a button \"FULL IMAGE\"\n",
    "        browser.find_by_id('full_image', wait_time=1).click()\n",
    "\n",
    "        #Click more info button\n",
    "        browser.find_by_css('[id=\"fancybox-lock\"]')[0].find_by_css('div[class=\"buttons\"] a:nth-child(2)')[0].click()\n",
    "        time.sleep(1)\n",
    "\n",
    "        #Take the image link (largesize)\n",
    "        featured_image_url = browser.find_by_css('figure[class=\"lede\"] a')['href']\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "            \n",
    "    #Close browser to avoid resource issue\n",
    "    browser.quit()\n",
    "\n",
    "    return featured_image_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "featured_image_url = scrape_featured_image_url()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://www.jpl.nasa.gov/spaceimages/images/largesize/PIA16613_hires.jpg'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "featured_image_url"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mars Weather - from twitter page\n",
    "\n",
    "* **Visit the Mars Weather twitter account and scrape the latest Mars weather tweet from the page. Save the tweet text for the weather report as a variable called mars_weather.**\n",
    "\n",
    "* **Note: Be sure you are not signed in to twitter, or scraping may become more difficult.**\n",
    "\n",
    "* **Note: Twitter frequently changes how information is presented on their website.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_mars_weather():\n",
    "    \n",
    "    #########################################################################################\n",
    "    #Scrape the latest Mars weather tweet from the twitter page\n",
    "    #Returns mars_weather\n",
    "    #########################################################################################\n",
    "    \n",
    "    mars_weather = None\n",
    "    #Configure Browser\n",
    "    browser = Browser(browser_choice, executable_path=executable_path, headless=True)\n",
    "    \n",
    "    try:\n",
    "        #Visit url\n",
    "        browser.visit(mars_twitter_page)\n",
    "        #bs object with lxml parser\n",
    "        time.sleep(4)#This is very important\n",
    "        soup = bs(browser.html, 'lxml')\n",
    "        #Extract the weather info using soup css selector\n",
    "        mars_weather = soup.find('div', attrs={'data-testid':'tweet'}).select('div:nth-of-type(2) > div:nth-of-type(2) > div:nth-of-type(1) > div:nth-of-type(1) > span')[0].text\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "            \n",
    "    #Close browser to avoid resource issue\n",
    "    browser.quit()\n",
    "    \n",
    "    return mars_weather\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'InSight sol 605 (2020-08-09) low -92.7ºC (-134.8ºF) high -18.4ºC (-1.1ºF)\\nwinds from the WNW at 8.8 m/s (19.7 mph) gusting to 22.5 m/s (50.4 mph)\\npressure at 7.90 hPa'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scrape_mars_weather()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mars Facts \n",
    "\n",
    "* **Visit the Mars Facts webpage here and use Pandas to scrape the table containing facts about the planet including Diameter, Mass, etc.**\n",
    "\n",
    "* **Use Pandas to convert the data to a HTML table string.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "DF = pd.read_html(mars_facts, attrs={'id':'tablepress-p-mars'})[0]\n",
    "DF.rename(columns={0:'attributes', 1:'value'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>attributes</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Equatorial Diameter:</td>\n",
       "      <td>6,792 km</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Polar Diameter:</td>\n",
       "      <td>6,752 km</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mass:</td>\n",
       "      <td>6.39 × 10^23 kg (0.11 Earths)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Moons:</td>\n",
       "      <td>2 (Phobos &amp; Deimos)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Orbit Distance:</td>\n",
       "      <td>227,943,824 km (1.38 AU)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Orbit Period:</td>\n",
       "      <td>687 days (1.9 years)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Surface Temperature:</td>\n",
       "      <td>-87 to -5 °C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>First Record:</td>\n",
       "      <td>2nd millennium BC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Recorded By:</td>\n",
       "      <td>Egyptian astronomers</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             attributes                          value\n",
       "0  Equatorial Diameter:                       6,792 km\n",
       "1       Polar Diameter:                       6,752 km\n",
       "2                 Mass:  6.39 × 10^23 kg (0.11 Earths)\n",
       "3                Moons:            2 (Phobos & Deimos)\n",
       "4       Orbit Distance:       227,943,824 km (1.38 AU)\n",
       "5         Orbit Period:           687 days (1.9 years)\n",
       "6  Surface Temperature:                   -87 to -5 °C\n",
       "7         First Record:              2nd millennium BC\n",
       "8          Recorded By:           Egyptian astronomers"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mars Hemispheres - from USGS Astrogeology site\n",
    "\n",
    "* **Visit the USGS Astrogeology site to obtain high resolution images for each of Mar's hemispheres.**\n",
    "\n",
    "* **Save both the image url string for the full resolution hemisphere image, and the Hemisphere title containing the hemisphere name. Use a Python dictionary to store the data using the keys img_url and title.**\n",
    "\n",
    "* **Append the dictionary with the image url string and the hemisphere title to a list. This list will contain one dictionary for each hemisphere.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_hemispheres():\n",
    "    \n",
    "    #########################################################################################\n",
    "    #Scrape high resolution images for each of Mar's hemispheres from USGS Astrogeology site\n",
    "    #Returns list of dictionaries with title and image urls\n",
    "    #########################################################################################\n",
    "    \n",
    "    hemisphere_image_urls = []\n",
    "    #Configure Browser\n",
    "    browser = Browser(browser_choice, executable_path=executable_path, headless=True)\n",
    "\n",
    "    try:\n",
    "        #Visit url\n",
    "        browser.visit(usgs_search)\n",
    "        #bs object with lxml parser\n",
    "        time.sleep(10)#This is very important (site loads super slow)\n",
    "        soup = bs(browser.html, 'lxml')\n",
    "        hs_links = soup.find(id='product-section').find_all('a',class_=\"itemLink product-item\")\n",
    "        for index,link in enumerate(hs_links):\n",
    "            if link.img is None:\n",
    "                title = re.sub(' Enhanced', '', link.text)\n",
    "            else:\n",
    "                browser.visit(usgs_base+link['href'])\n",
    "                time.sleep(1)\n",
    "                img_url = browser.find_by_css('img[class=\"wide-image\"]')['src']\n",
    "            \n",
    "            if index%2:#Image and title come together\n",
    "                hemisphere_image_urls.append({'title':title,'img_url':img_url})\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "            \n",
    "    #Close browser to avoid resource issue\n",
    "    browser.quit()\n",
    "    \n",
    "    return hemisphere_image_urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "hemisphere_image_urls = scrape_hemispheres()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'title': 'Cerberus Hemisphere',\n",
       "  'img_url': 'https://astrogeology.usgs.gov/cache/images/f5e372a36edfa389625da6d0cc25d905_cerberus_enhanced.tif_full.jpg'},\n",
       " {'title': 'Schiaparelli Hemisphere',\n",
       "  'img_url': 'https://astrogeology.usgs.gov/cache/images/3778f7b43bbbc89d6e3cfabb3613ba93_schiaparelli_enhanced.tif_full.jpg'},\n",
       " {'title': 'Syrtis Major Hemisphere',\n",
       "  'img_url': 'https://astrogeology.usgs.gov/cache/images/555e6403a6ddd7ba16ddb0e471cadcf7_syrtis_major_enhanced.tif_full.jpg'},\n",
       " {'title': 'Valles Marineris Hemisphere',\n",
       "  'img_url': 'https://astrogeology.usgs.gov/cache/images/b3c7c6c9138f57b4756be9b9c43e3a48_valles_marineris_enhanced.tif_full.jpg'}]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hemisphere_image_urls"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
